{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is the notebook for clustering states according to their demographics\n",
    "# first we will find the most deciding attributes on a state level\n",
    "# then we will rank these attributes (features)\n",
    "# and then we will cluster states"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": 106,
>>>>>>> fcce432cf04a92a187e1dc59da26277b1cff1398
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ranked_dataset is our master dataset that we will cluster over\n",
    "# we clone our original dataset, and replace all values with zero, before replacing them with their rank"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
=======
   "execution_count": 112,
>>>>>>> fcce432cf04a92a187e1dc59da26277b1cff1398
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cf = pd.read_csv(\"notebooks/county_facts_with_2012_winner.csv\")\n",
    "# cf\n",
    "list_of_states = cf[\"state_abbreviation\"].unique()\n",
    "# print list_of_states"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 113,
>>>>>>> fcce432cf04a92a187e1dc59da26277b1cff1398
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ExtraTreesClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-1136b99830d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# for each state, find and rank attributes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_of_states\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExtraTreesClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"winner\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ExtraTreesClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "# print cf\n",
    "cf = cf.drop(\"Gingrich\", 1)\n",
    "cf = cf.drop(\"Santorum\", 1)\n",
    "cf = cf.drop(\"Romney\", 1)\n",
    "cf = cf.drop(\"Paul\", 1)\n",
    "cf = cf.drop(\"fips\", 1)\n",
    "cf = cf.drop(\"area_name\", 1)\n",
    "\n",
    "# print cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AL\n",
      "[ 0.02726256  0.00778985  0.03038438  0.00370794  0.01770829  0.01166281\n",
      "  0.00362554  0.02401097  0.02549994  0.04727818  0.01062464  0.00652597\n",
      "  0.00418332  0.01788272  0.00517934  0.05557494  0.03650894  0.00863026\n",
      "  0.00271916  0.0283583   0.014191    0.01315207  0.01954494  0.02328305\n",
      "  0.02259684  0.01416551  0.03802257  0.01772323  0.02008543  0.00558644\n",
      "  0.01386256  0.00755765  0.02181909  0.03183672  0.03201405  0.01595392\n",
      "  0.0354468   0.02512593  0.00272263  0.00970513  0.          0.01335237\n",
      "  0.02582164  0.03464016  0.02959529  0.01293464  0.04074074  0.03461813\n",
      "  0.0297609   0.01241637  0.00660615]\n",
      "AZ\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "AR\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "CA\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "CO\n",
      "[ 0.          0.00895112  0.01363159  0.0310052   0.001582    0.02051913\n",
      "  0.05220058  0.02699115  0.00764396  0.01803033  0.01341197  0.02501672\n",
      "  0.02127617  0.03812925  0.00853658  0.01544954  0.03431137  0.02654132\n",
      "  0.01193538  0.02195134  0.0703095   0.00518769  0.03351025  0.00594089\n",
      "  0.00928667  0.0541271   0.0247386   0.027236    0.0011865   0.03095623\n",
      "  0.0307463   0.00569522  0.03896359  0.02598375  0.01700655  0.03159792\n",
      "  0.02580169  0.          0.01346636  0.00266963  0.          0.00234028\n",
      "  0.01541607  0.00059325  0.01478992  0.01657185  0.0399372   0.03202439\n",
      "  0.01372995  0.00830552  0.0047664 ]\n",
      "CT\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "DE\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "DC\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "FL\n",
      "[ 0.02978481  0.01664359  0.00100769  0.0064691   0.01885902  0.02270513\n",
      "  0.02999146  0.03211055  0.01548966  0.00136491  0.00447861  0.03495078\n",
      "  0.00497623  0.01565855  0.03513255  0.          0.00405789  0.\n",
      "  0.00379852  0.01152827  0.00676768  0.05715935  0.          0.01749715\n",
      "  0.00509159  0.06411132  0.00547386  0.04575421  0.00670133  0.00347432\n",
      "  0.03136525  0.00565158  0.00398099  0.00847053  0.00764481  0.00577885\n",
      "  0.02318339  0.          0.00690985  0.08178505  0.00123324  0.00266584\n",
      "  0.02857264  0.03281354  0.00311741  0.09923604  0.01505224  0.05054965\n",
      "  0.00796197  0.          0.08298901]\n",
      "GA\n",
      "[ 0.02548077  0.          0.          0.05497322  0.02264957  0.02264957\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.00452991  0.          0.02264957\n",
      "  0.          0.          0.04295434  0.03510684  0.          0.04076923\n",
      "  0.          0.02264957  0.03763314  0.02548077  0.          0.05662393\n",
      "  0.05945513  0.10806868  0.          0.          0.04555001  0.03142628\n",
      "  0.00566239  0.          0.          0.          0.          0.06228632\n",
      "  0.0974538   0.          0.02717949  0.          0.1147931   0.03397436\n",
      "  0.          0.        ]\n",
      "HI\n",
      "[ 0.          0.          0.          0.          0.06666667  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.08888889\n",
      "  0.          0.          0.          0.          0.          0.          0.2\n",
      "  0.          0.          0.03333333  0.          0.1         0.          0.\n",
      "  0.          0.1         0.          0.          0.2         0.          0.\n",
      "  0.          0.          0.01111111  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.2         0.        ]\n",
      "ID\n",
      "[ 0.01835506  0.00683895  0.01672659  0.02569082  0.0474134   0.09732878\n",
      "  0.0427458   0.0085549   0.04224852  0.03615508  0.0401145   0.01477261\n",
      "  0.01071161  0.04451231  0.          0.00620272  0.01977528  0.02409131\n",
      "  0.00704298  0.04416479  0.02517425  0.01390816  0.00594559  0.          0.014855\n",
      "  0.00659176  0.02876514  0.01732555  0.03518192  0.02886497  0.02228989\n",
      "  0.01371656  0.01029963  0.00837703  0.          0.01889638  0.00659176\n",
      "  0.          0.          0.          0.          0.01308609  0.01324543\n",
      "  0.00386632  0.01329535  0.01137079  0.01169122  0.02867425  0.02059925\n",
      "  0.05794464  0.01599707]\n",
      "IL\n",
      "[ 0.04977572  0.01423131  0.01329481  0.05057772  0.0171008   0.00519627\n",
      "  0.03122763  0.00262548  0.00883778  0.01254137  0.00717671  0.01306561\n",
      "  0.0157065   0.0214147   0.03085024  0.02200768  0.01875325  0.02027766\n",
      "  0.03260155  0.02730281  0.00664643  0.00908679  0.02408306  0.00940269\n",
      "  0.0111975   0.05192833  0.03873826  0.01293721  0.01022649  0.00614602\n",
      "  0.04889301  0.00909707  0.04934108  0.02719651  0.00372932  0.00764203\n",
      "  0.01206401  0.0211953   0.          0.04613105  0.          0.00656371\n",
      "  0.00753898  0.0134206   0.01985206  0.01984385  0.01300434  0.01199232\n",
      "  0.03672771  0.03030284  0.02050582]\n",
      "IN\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "IA\n",
      "[ 0.0111359   0.02188415  0.00851204  0.0051352   0.01756194  0.02244525\n",
      "  0.01479441  0.01637437  0.01124609  0.01574779  0.00939169  0.00995995\n",
      "  0.01892968  0.01628991  0.03072038  0.0171194   0.02521753  0.03734807\n",
      "  0.00202041  0.01761574  0.03798876  0.01161389  0.01463673  0.0225342\n",
      "  0.00951142  0.01729859  0.03901743  0.02544829  0.02460253  0.0194885\n",
      "  0.02295913  0.02029567  0.02825783  0.03032075  0.01359111  0.04425384\n",
      "  0.01961393  0.00971582  0.00485336  0.04714862  0.          0.0092602\n",
      "  0.00968589  0.01750766  0.00927316  0.02838816  0.02795394  0.03840907\n",
      "  0.02200132  0.00969252  0.0352278 ]\n",
      "KS\n",
      "[ 0.00939157  0.00851286  0.01323383  0.00448228  0.01232986  0.01406268\n",
      "  0.02657374  0.00921568  0.02463528  0.013567    0.06408831  0.00969382\n",
      "  0.02696224  0.02703499  0.03677045  0.02651151  0.02306662  0.01858102\n",
      "  0.01156053  0.0492668   0.02706696  0.00859297  0.02021675  0.01854964\n",
      "  0.0315938   0.01904488  0.02613565  0.00273628  0.00784221  0.04182996\n",
      "  0.0049743   0.01663634  0.03902015  0.0344264   0.04076963  0.0064754\n",
      "  0.03081071  0.          0.00753996  0.00222079  0.          0.\n",
      "  0.02596944  0.02386393  0.00990002  0.01831071  0.03221976  0.01772465\n",
      "  0.00325747  0.03777498  0.01495518]\n",
      "KY\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "LA\n",
      "[ 0.17460317  0.          0.03227513  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.08465608  0.          0.          0.          0.          0.\n",
      "  0.          0.          0.03227513  0.          0.1         0.\n",
      "  0.03227513  0.          0.          0.06772487  0.05079365  0.01534392\n",
      "  0.          0.05079365  0.03227513  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.11005291  0.06772487  0.          0.          0.14920635]\n",
      "nan\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 51)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-114-473b95a55464>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExtraTreesClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_data_winner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#     ranked_dataset[[i]][features] = features_importances_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \"\"\"\n\u001b[1;32m    211\u001b[0m         \u001b[0;31m# Validate or convert input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0;31m# Pre-sort indices to avoid that each individual tree of the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    405\u001b[0m                              \u001b[0;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m                              % (n_samples, shape_repr, ensure_min_samples,\n\u001b[0;32m--> 407\u001b[0;31m                                 context))\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_features\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 51)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "# for each state, find and rank attributes\n",
    "for i in list_of_states:\n",
    "    \n",
    "    print i\n",
    "    \n",
    "    state_data_winner = cf[cf[\"state_abbreviation\"]==i]['winner']    \n",
    "    state_data = cf[cf[\"state_abbreviation\"]==i]\n",
    "    state_data = state_data.drop(\"state_abbreviation\", 1)\n",
    "    state_data = state_data.drop(\"winner\", 1)\n",
    "    \n",
    "#     print state_data_winner.as_matrix()\n",
    "    \n",
    "    model = ExtraTreesClassifier()\n",
    "    model.fit(state_data.as_matrix(), state_data_winner.as_matrix())\n",
    "    print (model.feature_importances_)\n",
    "#     ranked_dataset[[i]][features] = features_importances_\n",
    "    \n",
    "# print ranked_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Feature Importance\n",
    "# from sklearn import datasets\n",
    "# from sklearn import metrics\n",
    "# from sklearn.ensemble import ExtraTreesClassifier\n",
    "# # load the iris datasets\n",
    "# dataset = datasets.load_iris()\n",
    "# # fit an Extra Trees model to the data\n",
    "# model = ExtraTreesClassifier()\n",
    "# model.fit(dataset.data, dataset.target)\n",
    "# # display the relative importance of each attribute\n",
    "# print(model.feature_importances_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
